{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0IrH+TgWyZrsr9yYU2SHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/endnef2/big_leader/blob/main/DL/Pytorch_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pytroch Autograd"
      ],
      "metadata": {
        "id": "2HrRUsBqUsMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aIXnjm8rUTkn"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "neW0D5jkU2AD",
        "outputId": "ab233735-fe02-4fd0-d26e-7a28f8be898a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3)\n",
        "y = x+2"
      ],
      "metadata": {
        "id": "aDrn0A-AU5qR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aML_tb-nVDFC",
        "outputId": "f4493b29-64ac-4d4e-fa27-70dfacb9a9a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0905,  0.9467, -0.7810])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7FQUS9oVFo8",
        "outputId": "b72821ef-f8e8-4956-a3be-836523cf27f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.0905, 2.9467, 1.2190])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*3"
      ],
      "metadata": {
        "id": "sViEA188VJzl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# z의 평균값\n",
        "z.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YibcQqzVUK4",
        "outputId": "fb700667-3438-4fa9-8315-5e29b6b1132b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(19.7201)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.mean().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtF2sSC2VUqv",
        "outputId": "cea00bd0-6538-4854-a37e-793e37a89a7a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.720109939575195"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2,2,requires_grad=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHZUNafxViGZ",
        "outputId": "76e8de13-b366-431a-8729-54c320ba0bf4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8292, 0.6482],\n",
              "        [0.4802, 0.4019]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paS9QydLWE-_",
        "outputId": "77370819-d79b-458f-dbe7-0bcb7a158635"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_gard 빼고 tensor valure 값만\n",
        "a.detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4Z3YCVWOJu",
        "outputId": "864cf422-8882-4a08-8207-7666692441db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8292, 0.6482],\n",
              "        [0.4802, 0.4019]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.no_gard()\n",
        "with torch.no_grad():\n",
        "  print((x**2).requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wEy2WWfWUgv",
        "outputId": "13e72f6a-05d8-474c-9d32-021cad1f1954"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.no_gard()\n",
        "with torch.no_grad():\n",
        "  print((x**2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKfS-8gNXC-O",
        "outputId": "d808ca5e-d2a6-453c-9178-3a498939a437"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.1891, 0.8963, 0.6100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.ones(4, requires_grad=True)\n",
        "\n",
        "# 학습시킬 때 파이토치는 for 문 사용\n",
        "for epoch in range(5):\n",
        "  model_out = (weight*3).sum()\n",
        "  model_out.backward()\n",
        "\n",
        "  print(weight.grad)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    weight-=0.1*weight.grad # weight 조정 weight = weight-0.1(learning rate)*weight.grad\n",
        "\n",
        "  weight.grad.zero_()\n",
        "\n",
        "print(weight)\n",
        "print(model_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugIB6c67XVxE",
        "outputId": "587d342c-1a01-4323-fb73-21724b111c93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([-0.5000, -0.5000, -0.5000, -0.5000], requires_grad=True)\n",
            "tensor(-2.4000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Backpropagation"
      ],
      "metadata": {
        "id": "2zKNDJ7YZHN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)"
      ],
      "metadata": {
        "id": "jGe_unt9Yp6J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(1.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "-nKpDju1ZVe1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = w * x"
      ],
      "metadata": {
        "id": "zfL2XTc3ZZnk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = (y-y_predict)**2"
      ],
      "metadata": {
        "id": "sHCPtIpdZkM2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vreSuF2JZq0y",
        "outputId": "e8267d26-bfb5-4651-a71c-735a6e4e9194"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "w.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oqpnAEtZsEz",
        "outputId": "7d4bd8ce-268e-4b47-9907-b11e6e559447"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w -= 0.01 *w.grad\n",
        "\n",
        "# 값을 0으로 바꿔라\n",
        "w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxNHppupaDIF",
        "outputId": "73afb8b0-550d-4133-c6f2-a5665d257fd9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Gradient Descent: Manually"
      ],
      "metadata": {
        "id": "L9KGsOpOa8DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([1,2,3,4], dtype=np.float32)\n",
        "Y = np.array([2,4,6,8], dtype=np.float32)\n",
        "\n",
        "w = 0.0 # 실수로 넣어주기"
      ],
      "metadata": {
        "id": "GXjFVFBdacDm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return w*x"
      ],
      "metadata": {
        "id": "hvi2k96nbajo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y, y_pred):\n",
        "  return ((y_pred-y)**2).mean()"
      ],
      "metadata": {
        "id": "jGGzAiVWbhaz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(x, y, y_pred):\n",
        "  return np.dot(2*x, y_pred-y).mean()\n",
        "print(forward(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpOvDTQIbyqd",
        "outputId": "0b86cd56-66bf-430f-c524-671ec896e421"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients 계산\n",
        "  dw = gradient(X, Y, y_pred) # input, output, 예측값\n",
        "\n",
        "  # update weight\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch%2==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.4f}')\n",
        "print(f'predict after training: f(5)={forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBqiE1yXcQho",
        "outputId": "65b4fde7-c70d-41fb-f471-c5a83ec8193f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 1.200, loss=30.0000\n",
            "epoch 3: w = 1.872, loss=0.7680\n",
            "epoch 5: w = 1.980, loss=0.0197\n",
            "epoch 7: w = 1.997, loss=0.0005\n",
            "epoch 9: w = 1.999, loss=0.0000\n",
            "epoch 11: w = 2.000, loss=0.0000\n",
            "epoch 13: w = 2.000, loss=0.0000\n",
            "epoch 15: w = 2.000, loss=0.0000\n",
            "epoch 17: w = 2.000, loss=0.0000\n",
            "epoch 19: w = 2.000, loss=0.0000\n",
            "predict after training: f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gradient Descent : Autograd"
      ],
      "metadata": {
        "id": "7AUGw16IkHfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
      ],
      "metadata": {
        "id": "v7lM_It5cycr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred-y)**2).mean()"
      ],
      "metadata": {
        "id": "cx47nsYbkcHL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # forward predict\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update weights\n",
        "  # w.data = w.data - learning_rate*w.grad\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate*w.grad\n",
        "\n",
        "  # update 후에 w를 zero화 시킨다.\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'epoch:{epoch+1}:w={w.item():.3f},loss={l.item():4f}')\n",
        "print(f'Prediction after training: f(5)={forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPZxGgM2ks90",
        "outputId": "837634c3-ee54-4ecc-8e12-f5abd48304db"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1:w=0.300,loss=30.000000\n",
            "epoch:11:w=1.665,loss=1.162786\n",
            "epoch:21:w=1.934,loss=0.045069\n",
            "epoch:31:w=1.987,loss=0.001747\n",
            "epoch:41:w=1.997,loss=0.000068\n",
            "epoch:51:w=1.999,loss=0.000003\n",
            "epoch:61:w=2.000,loss=0.000000\n",
            "epoch:71:w=2.000,loss=0.000000\n",
            "epoch:81:w=2.000,loss=0.000000\n",
            "epoch:91:w=2.000,loss=0.000000\n",
            "Prediction after training: f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Loss Function & Optimizer"
      ],
      "metadata": {
        "id": "jQtnnT85oaId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
      ],
      "metadata": {
        "id": "Ak3rYtaVntA4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return w*x"
      ],
      "metadata": {
        "id": "GzGY9pdDomBH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameter\n",
        "learning_rate = 0.01\n",
        "n_iters = 100"
      ],
      "metadata": {
        "id": "6xt2WaBDotfY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function and optimizer\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)"
      ],
      "metadata": {
        "id": "R_AN5zTRonX-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  # forward predict\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # update 후에 w를 zero화 시킨다.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print('epoch', epoch+1, ':w=', w, 'loss=', l)\n",
        "\n",
        "print(f'Prediction after training: f(5)={forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6EgPvugpTyg",
        "outputId": "7106dae3-3a7a-4884-a86b-43c92597b18d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 :w= tensor(0.3000, requires_grad=True) loss= tensor(30., grad_fn=<MseLossBackward0>)\n",
            "epoch 11 :w= tensor(1.6653, requires_grad=True) loss= tensor(1.1628, grad_fn=<MseLossBackward0>)\n",
            "epoch 21 :w= tensor(1.9341, requires_grad=True) loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
            "epoch 31 :w= tensor(1.9870, requires_grad=True) loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch 41 :w= tensor(1.9974, requires_grad=True) loss= tensor(6.7705e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch 51 :w= tensor(1.9995, requires_grad=True) loss= tensor(2.6244e-06, grad_fn=<MseLossBackward0>)\n",
            "epoch 61 :w= tensor(1.9999, requires_grad=True) loss= tensor(1.0176e-07, grad_fn=<MseLossBackward0>)\n",
            "epoch 71 :w= tensor(2.0000, requires_grad=True) loss= tensor(3.9742e-09, grad_fn=<MseLossBackward0>)\n",
            "epoch 81 :w= tensor(2.0000, requires_grad=True) loss= tensor(1.4670e-10, grad_fn=<MseLossBackward0>)\n",
            "epoch 91 :w= tensor(2.0000, requires_grad=True) loss= tensor(5.0768e-12, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5)=10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Advanced Training"
      ],
      "metadata": {
        "id": "yEbp4iVMvJZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원이 아닌 2차원으로 넣어야 error가 나지 않는다.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape"
      ],
      "metadata": {
        "id": "-9OdrQ_Gqn1I"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GldgwES1vrvy",
        "outputId": "61f666c6-539f-46b2-8616-65285c449b6e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = n_features\n",
        "output_size = Y.shape[1]"
      ],
      "metadata": {
        "id": "oQMHKtq5wjs8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model build\n",
        "model = nn.Linear(input_size, output_size)"
      ],
      "metadata": {
        "id": "1A6vi7m1wMe1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "      super(LinearRegression, self).__init__()\n",
        "      # define Layers\n",
        "      self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.lin(x)"
      ],
      "metadata": {
        "id": "2NsoV6vew0O0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression(input_size, output_size)"
      ],
      "metadata": {
        "id": "3rYcfKsXx6tZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_iters=100\n",
        "\n",
        "# loss function and optimizer\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "bjtWRRTUyKdA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  # forward predict\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # update 후에 w를 zero화 시킨다.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    w, b = model.parameters()\n",
        "    print('epoch', epoch+1, ':w=', w[0].item(), 'loss=', l)\n",
        "\n",
        "print(f'Prediction after training: f(5)={model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poax31C1zAHp",
        "outputId": "42faa2f4-719e-4673-eeef-b4455a0ef8d5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 :w= 0.05526984855532646 loss= tensor(33.1790, grad_fn=<MseLossBackward0>)\n",
            "epoch 11 :w= 1.3814436197280884 loss= tensor(1.0481, grad_fn=<MseLossBackward0>)\n",
            "epoch 21 :w= 1.6037887334823608 loss= tensor(0.2058, grad_fn=<MseLossBackward0>)\n",
            "epoch 31 :w= 1.6483174562454224 loss= tensor(0.1736, grad_fn=<MseLossBackward0>)\n",
            "epoch 41 :w= 1.6639856100082397 loss= tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
            "epoch 51 :w= 1.674760341644287 loss= tensor(0.1535, grad_fn=<MseLossBackward0>)\n",
            "epoch 61 :w= 1.6845040321350098 loss= tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
            "epoch 71 :w= 1.6938453912734985 loss= tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
            "epoch 81 :w= 1.7028924226760864 loss= tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
            "epoch 91 :w= 1.7116690874099731 loss= tensor(0.1207, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5)=9.422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6D7UYSuJz2VI"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}