{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq4WFCsIRyIjmW8lINgdMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/endnef2/big_leader/blob/main/DL/XOR_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch:XOR Problem"
      ],
      "metadata": {
        "id": "koU4hgF3CBWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. XOR Dataset"
      ],
      "metadata": {
        "id": "kbkSWkP6CNdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R1nuRzFIB_GE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0,0],\n",
        "                      [0,1],\n",
        "                      [1,0],\n",
        "                      [1,1]]).to(device)\n",
        "Y = torch.FloatTensor([[0],\n",
        "                       [1],\n",
        "                       [1],\n",
        "                       [0]]).to(device)"
      ],
      "metadata": {
        "id": "YqD2vQkDCYiL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKdzPktYCyTm",
        "outputId": "31a6c611-e999-4ee3-af64-0c74013d0f81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Perceptron 학습"
      ],
      "metadata": {
        "id": "bnDdYpVrDHvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(2, 1, bias=True)\n",
        "sigmoid = nn.Sigmoid()\n",
        "model = nn.Sequential(linear, sigmoid).to(device)"
      ],
      "metadata": {
        "id": "Dbjp9zpHDDtz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0,1 : 2진 분류\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "67CoGpMYD6yV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "for epoch in range(10001):\n",
        "  y_pred = model(X)\n",
        "  loss = criterion(y_pred, Y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 1000 ==0:\n",
        "    print(epoch, loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU0JUYdaESdr",
        "outputId": "fc2c69ef-53f3-4319-f5e6-b5735d10bc25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7245580554008484\n",
            "1000 0.6931473016738892\n",
            "2000 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "with torch.no_grad():\n",
        "  y_hat = (y_pred > 0.5).float() # 0.5 = threshold\n",
        "  accuracy = (y_hat == Y).float().mean()\n",
        "\n",
        "  print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iISc3HBmFbmd",
        "outputId": "cd301274-4291-4794-bbb1-9193b7ee7425"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat.detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5GuupBeGaDR",
        "outputId": "b8d63e9f-20f2-45e7-f3bd-6ba772455a38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtYQgfrMGhWq",
        "outputId": "4d59c1a8-b79b-4f98-8ad6-4fddde5b3fac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Multi-layered Perceptron 해결"
      ],
      "metadata": {
        "id": "7zVWjmc3GymM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구현\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 10, bias=True), # input layer\n",
        "    nn.ReLU(), # activation function\n",
        "    nn.Linear(10, 10, bias=True), # hidden layer\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1, bias=True), # output layer\n",
        "    nn.Sigmoid() # activation function\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "rOkh8UA3rPxe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0,1 : 2진 분류\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "cXpICutkH-DL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "for epoch in range(10001):\n",
        "  y_pred = model(X)\n",
        "  loss = criterion(y_pred, Y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 1000 ==0:\n",
        "    print(epoch, loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c-VzN9GIJDm",
        "outputId": "3fa63370-ef5f-4cfa-df37-363dfd9ef7e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6989635229110718\n",
            "1000 1.606661498954054e-05\n",
            "2000 2.0721181499538943e-06\n",
            "3000 7.502102903345076e-07\n",
            "4000 3.3004232591338223e-07\n",
            "5000 1.7989030709486542e-07\n",
            "6000 8.999686684774133e-08\n",
            "7000 5.993124574388276e-08\n",
            "8000 2.9988463268182386e-08\n",
            "9000 7.729750173268712e-11\n",
            "10000 6.146017722530317e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "with torch.no_grad():\n",
        "  y_hat = (y_pred > 0.5).float() # 0.5 = threshold\n",
        "  accuracy = (y_hat == Y).float().mean()\n",
        "\n",
        "  print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPbunZJQIO4E",
        "outputId": "51d4c9d8-947b-4739-8fd5-62f90e1fbd1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NY2EJWDPIUjX"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}